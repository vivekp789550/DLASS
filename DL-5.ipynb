{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "710c44a3-435b-45be-a3be-f9831724789b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0201a815-e1c1-4608-9c92-881862c07bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /home/rasika/.local/lib/python3.10/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /home/rasika/.local/lib/python3.10/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /home/rasika/.local/lib/python3.10/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/rasika/.local/lib/python3.10/site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in /home/rasika/.local/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "\u001b[33mWARNING: Error parsing dependencies of distro-info: Invalid version: '1.1build1'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of python-debian: Invalid version: '0.1.43ubuntu1'\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57732d15-e498-4ef2-bc8f-92809c800e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/rasika/.local/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: tensorflow in /home/rasika/.local/lib/python3.10/site-packages (2.17.0)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/rasika/.local/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/rasika/.local/lib/python3.10/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /home/rasika/.local/lib/python3.10/site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (1.67.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/rasika/.local/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: rich in /home/rasika/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (13.9.3)\n",
      "Requirement already satisfied: namex in /home/rasika/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/rasika/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rasika/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/rasika/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/rasika/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/rasika/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/rasika/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/rasika/.local/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/rasika/.local/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/rasika/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
      "\u001b[33mWARNING: Error parsing dependencies of distro-info: Invalid version: '1.1build1'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of python-debian: Invalid version: '0.1.43ubuntu1'\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4d5e35c-c4e5-4a77-b7bd-42ef1f0a4ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/rasika/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9107b48a-9c1f-4ebe-b574-f781e50cf6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/rasika/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579d0a5e-ab8b-4e41-8d3b-36a101af58f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "    tokens=word_tokenize(text.lower())\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    tokens=[word for word in tokens if word.isalpha() and word not in stop_words and word not in string.punctuation]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7563456b-71aa-445f-9ddf-cca0c23fee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample text for training the CBOW model\n",
    "text = \"Deep learning (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised. Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and Transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1a7912e-63e7-45f1-9976-b2b9b23ece61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deep', 'learning', 'known', 'deep']\n",
      "also\n",
      "*******************\n",
      "['learning', 'also', 'deep', 'structured']\n",
      "known\n",
      "*******************\n",
      "['also', 'known', 'structured', 'learning']\n",
      "deep\n",
      "*******************\n",
      "['known', 'deep', 'learning', 'part']\n",
      "structured\n",
      "*******************\n",
      "['deep', 'structured', 'part', 'broader']\n",
      "learning\n",
      "*******************\n",
      "['structured', 'learning', 'broader', 'family']\n",
      "part\n",
      "*******************\n",
      "['learning', 'part', 'family', 'machine']\n",
      "broader\n",
      "*******************\n",
      "['part', 'broader', 'machine', 'learning']\n",
      "family\n",
      "*******************\n",
      "['broader', 'family', 'learning', 'methods']\n",
      "machine\n",
      "*******************\n",
      "['family', 'machine', 'methods', 'based']\n",
      "learning\n",
      "*******************\n",
      "['machine', 'learning', 'based', 'artificial']\n",
      "methods\n",
      "*******************\n",
      "['learning', 'methods', 'artificial', 'neural']\n",
      "based\n",
      "*******************\n",
      "['methods', 'based', 'neural', 'networks']\n",
      "artificial\n",
      "*******************\n",
      "['based', 'artificial', 'networks', 'representation']\n",
      "neural\n",
      "*******************\n",
      "['artificial', 'neural', 'representation', 'learning']\n",
      "networks\n",
      "*******************\n",
      "['neural', 'networks', 'learning', 'learning']\n",
      "representation\n",
      "*******************\n",
      "['networks', 'representation', 'learning', 'supervised']\n",
      "learning\n",
      "*******************\n",
      "['representation', 'learning', 'supervised', 'unsupervised']\n",
      "learning\n",
      "*******************\n",
      "['learning', 'learning', 'unsupervised', 'architectures']\n",
      "supervised\n",
      "*******************\n",
      "['learning', 'supervised', 'architectures', 'deep']\n",
      "unsupervised\n",
      "*******************\n",
      "['supervised', 'unsupervised', 'deep', 'neural']\n",
      "architectures\n",
      "*******************\n",
      "['unsupervised', 'architectures', 'neural', 'networks']\n",
      "deep\n",
      "*******************\n",
      "['architectures', 'deep', 'networks', 'deep']\n",
      "neural\n",
      "*******************\n",
      "['deep', 'neural', 'deep', 'belief']\n",
      "networks\n",
      "*******************\n",
      "['neural', 'networks', 'belief', 'networks']\n",
      "deep\n",
      "*******************\n",
      "['networks', 'deep', 'networks', 'deep']\n",
      "belief\n",
      "*******************\n",
      "['deep', 'belief', 'deep', 'reinforcement']\n",
      "networks\n",
      "*******************\n",
      "['belief', 'networks', 'reinforcement', 'learning']\n",
      "deep\n",
      "*******************\n",
      "['networks', 'deep', 'learning', 'recurrent']\n",
      "reinforcement\n",
      "*******************\n",
      "['deep', 'reinforcement', 'recurrent', 'neural']\n",
      "learning\n",
      "*******************\n",
      "['reinforcement', 'learning', 'neural', 'networks']\n",
      "recurrent\n",
      "*******************\n",
      "['learning', 'recurrent', 'networks', 'convolutional']\n",
      "neural\n",
      "*******************\n",
      "['recurrent', 'neural', 'convolutional', 'neural']\n",
      "networks\n",
      "*******************\n",
      "['neural', 'networks', 'neural', 'networks']\n",
      "convolutional\n",
      "*******************\n",
      "['networks', 'convolutional', 'networks', 'transformers']\n",
      "neural\n",
      "*******************\n",
      "['convolutional', 'neural', 'transformers', 'applied']\n",
      "networks\n",
      "*******************\n",
      "['neural', 'networks', 'applied', 'fields']\n",
      "transformers\n",
      "*******************\n",
      "['networks', 'transformers', 'fields', 'including']\n",
      "applied\n",
      "*******************\n",
      "['transformers', 'applied', 'including', 'computer']\n",
      "fields\n",
      "*******************\n",
      "['applied', 'fields', 'computer', 'vision']\n",
      "including\n",
      "*******************\n",
      "['fields', 'including', 'vision', 'speech']\n",
      "computer\n",
      "*******************\n",
      "['including', 'computer', 'speech', 'recognition']\n",
      "vision\n",
      "*******************\n",
      "['computer', 'vision', 'recognition', 'natural']\n",
      "speech\n",
      "*******************\n",
      "['vision', 'speech', 'natural', 'language']\n",
      "recognition\n",
      "*******************\n",
      "['speech', 'recognition', 'language', 'processing']\n",
      "natural\n",
      "*******************\n",
      "['recognition', 'natural', 'processing', 'machine']\n",
      "language\n",
      "*******************\n",
      "['natural', 'language', 'machine', 'translation']\n",
      "processing\n",
      "*******************\n",
      "['language', 'processing', 'translation', 'bioinformatics']\n",
      "machine\n",
      "*******************\n",
      "['processing', 'machine', 'bioinformatics', 'drug']\n",
      "translation\n",
      "*******************\n",
      "['machine', 'translation', 'drug', 'design']\n",
      "bioinformatics\n",
      "*******************\n",
      "['translation', 'bioinformatics', 'design', 'medical']\n",
      "drug\n",
      "*******************\n",
      "['bioinformatics', 'drug', 'medical', 'image']\n",
      "design\n",
      "*******************\n",
      "['drug', 'design', 'image', 'analysis']\n",
      "medical\n",
      "*******************\n",
      "['design', 'medical', 'analysis', 'climate']\n",
      "image\n",
      "*******************\n",
      "['medical', 'image', 'climate', 'science']\n",
      "analysis\n",
      "*******************\n",
      "['image', 'analysis', 'science', 'material']\n",
      "climate\n",
      "*******************\n",
      "['analysis', 'climate', 'material', 'inspection']\n",
      "science\n",
      "*******************\n",
      "['climate', 'science', 'inspection', 'board']\n",
      "material\n",
      "*******************\n",
      "['science', 'material', 'board', 'game']\n",
      "inspection\n",
      "*******************\n",
      "['material', 'inspection', 'game', 'programs']\n",
      "board\n",
      "*******************\n",
      "['inspection', 'board', 'programs', 'produced']\n",
      "game\n",
      "*******************\n",
      "['board', 'game', 'produced', 'results']\n",
      "programs\n",
      "*******************\n",
      "['game', 'programs', 'results', 'comparable']\n",
      "produced\n",
      "*******************\n",
      "['programs', 'produced', 'comparable', 'cases']\n",
      "results\n",
      "*******************\n",
      "['produced', 'results', 'cases', 'surpassing']\n",
      "comparable\n",
      "*******************\n",
      "['results', 'comparable', 'surpassing', 'human']\n",
      "cases\n",
      "*******************\n",
      "['comparable', 'cases', 'human', 'expert']\n",
      "surpassing\n",
      "*******************\n",
      "['cases', 'surpassing', 'expert', 'performance']\n",
      "human\n",
      "*******************\n",
      "[['deep', 'learning', 'known', 'deep', 'also'], ['learning', 'also', 'deep', 'structured', 'known'], ['also', 'known', 'structured', 'learning', 'deep'], ['known', 'deep', 'learning', 'part', 'structured'], ['deep', 'structured', 'part', 'broader', 'learning'], ['structured', 'learning', 'broader', 'family', 'part'], ['learning', 'part', 'family', 'machine', 'broader'], ['part', 'broader', 'machine', 'learning', 'family'], ['broader', 'family', 'learning', 'methods', 'machine'], ['family', 'machine', 'methods', 'based', 'learning'], ['machine', 'learning', 'based', 'artificial', 'methods'], ['learning', 'methods', 'artificial', 'neural', 'based'], ['methods', 'based', 'neural', 'networks', 'artificial'], ['based', 'artificial', 'networks', 'representation', 'neural'], ['artificial', 'neural', 'representation', 'learning', 'networks'], ['neural', 'networks', 'learning', 'learning', 'representation'], ['networks', 'representation', 'learning', 'supervised', 'learning'], ['representation', 'learning', 'supervised', 'unsupervised', 'learning'], ['learning', 'learning', 'unsupervised', 'architectures', 'supervised'], ['learning', 'supervised', 'architectures', 'deep', 'unsupervised'], ['supervised', 'unsupervised', 'deep', 'neural', 'architectures'], ['unsupervised', 'architectures', 'neural', 'networks', 'deep'], ['architectures', 'deep', 'networks', 'deep', 'neural'], ['deep', 'neural', 'deep', 'belief', 'networks'], ['neural', 'networks', 'belief', 'networks', 'deep'], ['networks', 'deep', 'networks', 'deep', 'belief'], ['deep', 'belief', 'deep', 'reinforcement', 'networks'], ['belief', 'networks', 'reinforcement', 'learning', 'deep'], ['networks', 'deep', 'learning', 'recurrent', 'reinforcement'], ['deep', 'reinforcement', 'recurrent', 'neural', 'learning'], ['reinforcement', 'learning', 'neural', 'networks', 'recurrent'], ['learning', 'recurrent', 'networks', 'convolutional', 'neural'], ['recurrent', 'neural', 'convolutional', 'neural', 'networks'], ['neural', 'networks', 'neural', 'networks', 'convolutional'], ['networks', 'convolutional', 'networks', 'transformers', 'neural'], ['convolutional', 'neural', 'transformers', 'applied', 'networks'], ['neural', 'networks', 'applied', 'fields', 'transformers'], ['networks', 'transformers', 'fields', 'including', 'applied'], ['transformers', 'applied', 'including', 'computer', 'fields'], ['applied', 'fields', 'computer', 'vision', 'including'], ['fields', 'including', 'vision', 'speech', 'computer'], ['including', 'computer', 'speech', 'recognition', 'vision'], ['computer', 'vision', 'recognition', 'natural', 'speech'], ['vision', 'speech', 'natural', 'language', 'recognition'], ['speech', 'recognition', 'language', 'processing', 'natural'], ['recognition', 'natural', 'processing', 'machine', 'language'], ['natural', 'language', 'machine', 'translation', 'processing'], ['language', 'processing', 'translation', 'bioinformatics', 'machine'], ['processing', 'machine', 'bioinformatics', 'drug', 'translation'], ['machine', 'translation', 'drug', 'design', 'bioinformatics'], ['translation', 'bioinformatics', 'design', 'medical', 'drug'], ['bioinformatics', 'drug', 'medical', 'image', 'design'], ['drug', 'design', 'image', 'analysis', 'medical'], ['design', 'medical', 'analysis', 'climate', 'image'], ['medical', 'image', 'climate', 'science', 'analysis'], ['image', 'analysis', 'science', 'material', 'climate'], ['analysis', 'climate', 'material', 'inspection', 'science'], ['climate', 'science', 'inspection', 'board', 'material'], ['science', 'material', 'board', 'game', 'inspection'], ['material', 'inspection', 'game', 'programs', 'board'], ['inspection', 'board', 'programs', 'produced', 'game'], ['board', 'game', 'produced', 'results', 'programs'], ['game', 'programs', 'results', 'comparable', 'produced'], ['programs', 'produced', 'comparable', 'cases', 'results'], ['produced', 'results', 'cases', 'surpassing', 'comparable'], ['results', 'comparable', 'surpassing', 'human', 'cases'], ['comparable', 'cases', 'human', 'expert', 'surpassing'], ['cases', 'surpassing', 'expert', 'performance', 'human']]\n"
     ]
    }
   ],
   "source": [
    "tokens=pre_process(text)\n",
    "training_data=[]\n",
    "context_size=2\n",
    "for i in range (context_size , len(tokens)-context_size):\n",
    "    context=tokens[i-context_size:i]+tokens[i+1:i+1+context_size]\n",
    "    target=tokens[i]\n",
    "    training_data.append(context+[target])\n",
    "    print(context)\n",
    "    print(target)\n",
    "    print(\"*******************\")\n",
    "\n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bc62d9f-134b-4ca5-970f-473de0c3576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Word2Vec(sentences=training_data , vector_size=500 , sg=0 , min_count=1 , workers=4, window=context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e80a26c-ca05-40a8-a0e9-25a146924c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1901, 6800)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(training_data , total_examples=len(training_data) , epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "867bd382-35f9-423e-b702-d44c53cce53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    i=random.randint(2 , len(tokens)-3)\n",
    "    prev_words=tokens[i-2:i]\n",
    "    next_words=tokens[i+1:i+3]\n",
    "    predict_word=model.predict_output_word(prev_words+next_words , topn=1)\n",
    "    print(f\"Context words are: {prev_words+next_words}\")\n",
    "    print(f\"target word is: {predict_word}\")\n",
    "\n",
    "    print(f\"Most similar words to : {predict_word}\")\n",
    "    similar_words=model.wv.most_similar(predict_word , topn=5)\n",
    "    for word , similarity in similar_words:\n",
    "        print(f\"{word}:{similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1f2c306-7bda-48d8-b0c7-b86405f6194a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context words are: ['image', 'analysis', 'science', 'material']\n",
      "target word is: [('climate', 0.018182563)]\n",
      "Most similar words to : [('climate', 0.018182563)]\n",
      "learning:0.12924546003341675\n",
      "bioinformatics:0.12154877185821533\n",
      "recognition:0.12113896757364273\n",
      "reinforcement:0.11861458420753479\n",
      "inspection:0.1157972514629364\n"
     ]
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3a46f2-6dc1-4c95-b7e4-ad3582bf2a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
